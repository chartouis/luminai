# LuminAI Backend

This is the backend service for **LuminAI**, an AI-powered cinematic video generation system.  
It transforms plain text into short narrated video clips with visuals, audio, and atmosphere â€” all generated automatically through a multi-stage pipeline.

---

## ğŸ§© Overview

The backend exposes three main endpoints under `/api/upload/`:

| Endpoint | Method | Description |
|-----------|--------|-------------|
| `/text` | `POST` | Accepts raw input text and a number of scenes to generate. Sends the text to an LLM which returns structured JSON with scene definitions. |
| `/states` | `GET` | Returns the current processing queue of all scenes and their statuses. |
| `/video/{id}` | `GET` | Once all scenes for a batch are complete, concatenates all generated videos into one final video and returns its path. |

---

## âš™ï¸ Pipeline

### 1. LLM (Scene Generation)
The backend sends the given text and scene number to **OpenAI GPT-4o-mini**.  
The LLM returns a JSON array describing each scene.

Each scene includes:
```
scene
script
photoPrompt
audioPrompt
backgroundPrompt
```

### 2. Seedream (Image Generation)
```
â†’ Each sceneâ€™s photoPrompt is sent to Higgsfield Seedream API.
â†’ API returns an image job ID.
â†’ The job is tracked until status = FINISHED.
â†’ The resulting image URL is stored in memory.
```

### 3. VEO3 (Video Generation)
```
â†’ Once an image is ready, Higgsfield VEO3 API is triggered with:
   - script
   - audioPrompt
   - backgroundPrompt
   - image_url
â†’ Returns video job ID.
â†’ The job is polled until complete.
â†’ Final video URL is stored in queue.
```

### 4. Video Concatenation
```
â†’ After all scenes in a batch are finished:
   - Download all video URLs.
   - Concatenate them using FFmpeg.
â†’ Final output: src/main/resources/videos/{batchId}.mp4
```

---

## ğŸ” Queue System
```
HashMap<UUID, State> queue
```

Each State includes:
```
id
batchId
scene
imgStatus / vidStatus
imgurl / vidurl
```

A scheduled task runs every 10 seconds to:
```
- Check job status on Higgsfield
- Update URLs when done
- Trigger next stage automatically
```

---

## ğŸ“¡ Environment Variables
```
OPEN_AI_KEY        â†’ OpenAI API key
API_KEY_HIGGS      â†’ Higgsfield public key
API_SECRET_HIGGS   â†’ Higgsfield secret key
```

---

## ğŸ§° Technologies
```
Java 23
Spring Boot
Gradle
Unirest (HTTP)
Jackson (JSON)
FFmpeg (video concatenation)
OpenAI GPT-4o-mini
Higgsfield Seedream & VEO3 APIs
```

---

## ğŸš€ How It Works
```
1. /upload/text   â†’ send text â†’ returns batchId
2. Scheduler auto-tracks generation
3. /upload/states â†’ monitor queue progress
4. /upload/video/{batchId} â†’ returns final video file path
```

---

## ğŸ§© Example Flow
```
POST /api/upload/text
{
  "text": "The town celebrated the opening of a new park.",
  "scene_number": 3
}
```

Response:
```
{
  "batchId": "b22eaf23-...-451c"
}
```

After completion:
```
GET /api/upload/video/b22eaf23-...-451c
```

Returns:
```
src/main/resources/videos/b22eaf23-...-451c.mp4
```

---

## ğŸ§  Notes
```
- LLM output must be valid JSON.
- Polling interval: 10 seconds.
- All jobs are stored in-memory.
- Persistent storage (DB, S3) can be added later.
```

---

## ğŸª„ Summary
```
Text
â†’ LLM
â†’ Scenes
â†’ Seedream (Images)
â†’ VEO3 (Videos)
â†’ FFmpeg (Concatenation)
```

LuminAI backend orchestrates the entire creative chain â€” from plain text to a finished cinematic video.
